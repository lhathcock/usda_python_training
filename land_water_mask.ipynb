{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78eda0d9-36d2-430b-9005-4bacb309bac7",
   "metadata": {},
   "source": [
    "# Python Learn By Doing - Land/Water Masking\n",
    "\n",
    "**Author:** Lee Hathcock, Mississippi State University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe10388-9228-4671-afe1-76f5e0a2f3c2",
   "metadata": {},
   "source": [
    "## A Brief Primer on Land/Water Masks\n",
    "\n",
    "There are several ways to attempt to produce a land/water mask, but one way that is used \n",
    "(as defined by McFeeters 1996) is calculating NDWI, or Normalized Difference Water Index.\n",
    "\n",
    "As originally defined, NDWI used the NIR and SWIR bands. This is sensitive to moisture content in leaves.\n",
    "If we want to look at simple land/water body delineation, then using the McFeeters method, which uses the\n",
    "Green band in place of SWIR.\n",
    "\n",
    "There is also the Modified NDWI (or MNDWI), which purports to improve the McFeeters version by replacing NIR with\n",
    "SWIR. The dataset we're using today does not have SWIR, but does have Green and NIR.\n",
    "\n",
    "As defined by the index, we are looking at the following ranges for various land/water entities.\n",
    "\n",
    "| Value | Class |\n",
    "|-----|-----|\n",
    "| 0.0 to 0.2 | Humidity/flooding |\n",
    "| 0.2 to 1.0 | Water surface |\n",
    "|-0.3 to 0.0 | Moderate drought, non-aqueous surface |\n",
    "|-1.0 to -0.3 | Drought, non-aqueous surface |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac2f9a-8e90-4d9e-a389-bf35cc4abbad",
   "metadata": {},
   "source": [
    "## Sensor Description\n",
    "\n",
    "The included GeoTIFF files were produced from imagery captured using a MicaSense RedEdge-MX camera, which has five spectral bands: Blue, Green, Red, Red Edge, and NIR. The imagery was processed into a mosaic using Pix4Dmapper, and is reflectance-corrected using either the provided reference panel or an 11% calibration tarp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2138d-9a89-406f-a5bb-1106da6b9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in our libraries - GDAL and OSR for reading GeoTIFFs, NumPy for array\n",
    "# manipulation, matplotlib for displaying imagery\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "from osgeo import ogr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import cv2\n",
    "from urllib.request import urlretrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21fb2c-9d05-4cae-be12-9b20dd6a22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder for data downloads\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "\n",
    "# info for shapefile to be downloaded\n",
    "base_filename='data/2021-11-04_Turnage_Florida_Flight2_Clip_BGREN'\n",
    "tif_info=  {'.tif':'https://osf.io/k3xm8/download',\n",
    "            '.tfw':'https://osf.io/ne8af/download',\n",
    "            '.tif.aux.xml':'https://osf.io/xhgkb/download',\n",
    "            '.tif.ovr':'https://osf.io/z5tnw/download'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b72906-c1db-4017-8956-9588cad11947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this cell once to download imagery\n",
    "for ext,url in tif_info.items():\n",
    "    filename=base_filename+ext\n",
    "    print('downloading',filename)\n",
    "    urlretrieve(url,filename) # download and save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d95f2-30b0-4b4c-afd1-abec55c49e84",
   "metadata": {},
   "source": [
    "## Opening Files With GDAL\n",
    "\n",
    "We use the \"Open\" command of GDAL to get a pointer to a file object. Put the file name in quotes\n",
    "if you're already in the correct directory (i.e. in the same folder as the notebook), but if in\n",
    "a different directory, then you need to give a full file path to the data.\n",
    "\n",
    "We also want to grab our projection and spatial reference. We can easily get this from a GeoTIFF\n",
    "using the \"GetProjection\" function, and then parse the Well-Known Text (WKT) we retrieved using\n",
    "the \"SpatialReference\" function to create a projection object that we can use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c22dda-9828-435f-b94d-9e6bbcb9f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image file\n",
    "img = gdal.Open(base_filename+'.tif')\n",
    "\n",
    "# Get our image's geographic information\n",
    "geotransform = img.GetGeoTransform()\n",
    "wkt = img.GetProjection()\n",
    "proj = osr.SpatialReference(wkt)\n",
    "\n",
    "print (geotransform, \"\\n\")\n",
    "print (wkt, \"\\n\")\n",
    "print (proj, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36faa179-abcb-4043-9d8e-4a8887d1ecbe",
   "metadata": {},
   "source": [
    "## Reading Raster Bands and Putting Into NumPy Arrays\n",
    "\n",
    "To retrieve a raster band, we use the \"GetRasterBand\" function. Note that these are indexed starting from one, not zero, so be careful\n",
    "that you choose the correct band. This selects the band, but we also need to get it into an array to work with, so we use the\n",
    "\"ReadAsArray\" function to read that raster band into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031bdde1-4bd4-4012-b062-8a305d7f17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our five bands. Note that you may not need all bands, but for\n",
    "# availability we're going to bring in all of them.\n",
    "\n",
    "# This will put the raster values for each band into a NumPy array.\n",
    "\n",
    "blue = img.GetRasterBand(1).ReadAsArray()\n",
    "green = img.GetRasterBand(2).ReadAsArray()\n",
    "red = img.GetRasterBand(3).ReadAsArray()\n",
    "rededge = img.GetRasterBand(4).ReadAsArray()\n",
    "nir = img.GetRasterBand(5).ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e903a5-0c11-4e8c-99ec-69ae52ef31c8",
   "metadata": {},
   "source": [
    "## Handling NoData Values\n",
    "\n",
    "In most GeoTIFFs, a value has been defined as a \"NoData\" value. This is a value that various software will\n",
    "treat as non-existent and not operate on those values. When we get these values, we want to go ahead and\n",
    "tell NumPy that this particular value shouldn't be used, so we will turn all of those values to NaN using\n",
    "the \"where\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a2f56-b6ef-4152-9816-b2114374a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our nodata value\n",
    "\n",
    "# This may actually change based on each band - probably not common, but\n",
    "# still possible.\n",
    "\n",
    "nodata = img.GetRasterBand(1).GetNoDataValue()\n",
    "blue = np.where(blue == nodata, np.nan, blue)\n",
    "nodata = img.GetRasterBand(2).GetNoDataValue()\n",
    "green = np.where(green == nodata, np.nan, green)\n",
    "nodata = img.GetRasterBand(3).GetNoDataValue()\n",
    "red = np.where(red == nodata, np.nan, red)\n",
    "nodata = img.GetRasterBand(4).GetNoDataValue()\n",
    "rededge = np.where(rededge == nodata, np.nan, rededge)\n",
    "nodata = img.GetRasterBand(5).GetNoDataValue()\n",
    "nir = np.where(nir == nodata, np.nan, nir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a9b8c-8e14-4739-a7a2-8bb4e6525244",
   "metadata": {},
   "source": [
    "## Changing the Size of Displayed Imagery\n",
    "\n",
    "Some imagery might display rather small (or large), depending on what you're working with. In this case, it's useful to\n",
    "change the DPI. There are other ways to change the size, including hard-coding the image size, but changing the DPI is\n",
    "often the quickest way to adjust as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010287c-6a38-413b-94f9-0838704f30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The easiest way to change the display scale for imagery is to change the DPI.\n",
    "# The larger the number, the more it will slow things down.\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191b844-2b7a-4d6f-8d5f-b4cabced68c5",
   "metadata": {},
   "source": [
    "## Displaying Imagery\n",
    "\n",
    "We imported pyplot from matplotlib, so let's use the imshow function to display our array in the notebook.\n",
    "\n",
    "Notice that you may end up with issues visualizing if you don't do a histogram stretch\n",
    "similar to ArcGIS, as we can see below. By default, this is doing a min-max stretch on the data, which means just\n",
    "a few bright or dark pixel outliers can skew the displayed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde7fdf-f5a7-48f5-b189-ead1fc171957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at our data...\n",
    "imblue = plt.imshow(blue)\n",
    "\n",
    "# Looks a bit dark! Let's see if we can address that in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad972c7-769f-4ffb-8d39-ab444505edc4",
   "metadata": {},
   "source": [
    "## Applying a stretch to the data\n",
    "\n",
    "Much like ArcGIS, we can apply various stretches to normalize the data and make it easier to view. There\n",
    "may be a fancier, faster way to do this, but we're going to leverage computing our own values for the imagery\n",
    "bounds.\n",
    "\n",
    "### Standard deviation stretch\n",
    "\n",
    "Using NumPy, we calculate our mean and standard deviation, then compute the ranges on\n",
    "each side. This gets passed to a Normalize function, which will be used when displaying the data.\n",
    "The color maps can also be specified here if the default isn't appropriate for displaying the data.\n",
    "\n",
    "The Normalize function is effectively setting values that are above and below the computed threshold to\n",
    "the minimum and maximum value in the image. So all values below two standard deviations below the mean will\n",
    "be displayed as the lowest displayed value, and all values above two standard deviations will be displayed\n",
    "as the highest displayed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca68d4-73e2-4144-88b1-5345adb97fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab our standard deviation and mean. Will need it so we can scale our imagery\n",
    "# more effectively. Currently using two standard deviations.\n",
    "stdev = np.nanstd(blue)\n",
    "mean = np.nanmean(blue)\n",
    "\n",
    "print(\"Standard deviation: \", stdev)\n",
    "print(\"Mean: \", mean)\n",
    "\n",
    "blue_min_std = mean - (stdev*2)\n",
    "blue_max_std = mean + (stdev*2)\n",
    "\n",
    "print (\"Min value:\", blue_min_std)\n",
    "print (\"Max value:\", blue_max_std)\n",
    "\n",
    "# This calls our normalization function. The color map can be changed in the imshow\n",
    "# call - there are many built-in options, and custom color maps can also be used.\n",
    "normalize = colors.Normalize(vmin=blue_min_std, vmax=blue_max_std, clip=True)\n",
    "imblue = plt.imshow(blue, cmap='Blues_r', norm=normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae887548-e0ad-46bb-84cd-95931ae09f1e",
   "metadata": {},
   "source": [
    "### Percent clip stretch\n",
    "\n",
    "Sometimes standard deviation stretches look great, but in this case, it feels a bit washed out, so let's\n",
    "try a percent clip instead. Instead of using standard deviation, this will instead discard a certain percentage\n",
    "of values, setting anything above and below to max and min values. This is very good to eliminate outlier values.\n",
    "We can compute this using NumPy's percentile function.\n",
    "\n",
    "In this case, we're going to clip two percent from the top and bottom of our dataset.\n",
    "\n",
    "#### Quick note regarding the percentile function\n",
    "\n",
    "To compute the boundary values, there are several methods to choose what those values are. In this case,\n",
    "we're using linear, which interpolates values and as such the boundary value might not exist in the list.\n",
    "This may or may not be okay depending on your dataset. Note that this option used to be \"interpolation\"\n",
    "but is now \"method\", so be aware if you're using an older version of NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8d8c7-9db4-46a6-adb0-fca5f5dcaa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we don't want to do a standard deviation stretch, but instead a percent clip. We can do this using\n",
    "# NumPy's percentile function.\n",
    "\n",
    "# Note that using \"linear\" will interpolate and produce values that may not exist in the array. This is\n",
    "# fine for what we're doing, as we just want lower and upper bounds to adjust our data display range.\n",
    "\n",
    "# May not work if older version of NumPy, changed from \"interpolation\" to \"method\", so add try/except block.\n",
    "try:\n",
    "    perc = np.percentile(blue, [2, 98], method=\"linear\")\n",
    "except:\n",
    "    perc = np.percentile(blue, [2, 98], interpolation=\"linear\")\n",
    "\n",
    "print (perc)\n",
    "\n",
    "# Call our normalize function as before.\n",
    "normalize = colors.Normalize(vmin=perc[0], vmax=perc[1], clip=True)\n",
    "imblue = plt.imshow(blue, cmap='Blues_r', norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55d2b1-6acd-44e0-885b-75764eae8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating for each band.\n",
    "\"\"\"\n",
    "stdev = np.nanstd(green)\n",
    "mean = np.nanmean(green)\n",
    "\n",
    "print(stdev)\n",
    "print(mean)\n",
    "\n",
    "green_min_std = mean - (stdev*2)\n",
    "green_max_std = mean + (stdev*2)\n",
    "\n",
    "normalize = colors.Normalize(vmin=green_min_std, vmax=green_max_std, clip=True)\n",
    "imgreen = plt.imshow(green, cmap='Greens_r', norm=normalize)\n",
    "\"\"\"\n",
    "\n",
    "# May not work if older version of NumPy, changed from \"interpolation\" to \"method\", so add try/except block.\n",
    "try:\n",
    "    perc = np.percentile(green, [2, 98], method=\"linear\")\n",
    "except:\n",
    "    perc = np.percentile(green, [2, 98], interpolation=\"linear\")\n",
    "\n",
    "print (perc)\n",
    "\n",
    "# Call our normalize function as before.\n",
    "normalize = colors.Normalize(vmin=perc[0], vmax=perc[1], clip=True)\n",
    "imgreen = plt.imshow(green, cmap='Greens_r', norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c09ff-060a-4f0c-8181-eff20a897de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "stdev = np.nanstd(red)\n",
    "mean = np.nanmean(red)\n",
    "\n",
    "print(stdev)\n",
    "print(mean)\n",
    "\n",
    "red_min_std = mean - (stdev*2)\n",
    "red_max_std = mean + (stdev*2)\n",
    "\n",
    "normalize = colors.Normalize(vmin=red_min_std, vmax=red_max_std, clip=True)\n",
    "imred = plt.imshow(red, cmap='Reds_r', norm=normalize)\n",
    "\"\"\"\n",
    "# May not work if older version of NumPy, changed from \"interpolation\" to \"method\", so add try/except block.\n",
    "try:\n",
    "    perc = np.percentile(red, [2, 98], method=\"linear\")\n",
    "except:\n",
    "    perc = np.percentile(red, [2, 98], interpolation=\"linear\")\n",
    "\n",
    "print (perc)\n",
    "\n",
    "# Call our normalize function as before.\n",
    "normalize = colors.Normalize(vmin=perc[0], vmax=perc[1], clip=True)\n",
    "imred = plt.imshow(red, cmap='Reds_r', norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c008aea-b36e-480f-b354-cb28b42cfb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "stdev = np.nanstd(rededge)\n",
    "mean = np.nanmean(rededge)\n",
    "\n",
    "print(stdev)\n",
    "print(mean)\n",
    "\n",
    "rededge_min_std = mean - (stdev*2)\n",
    "rededge_max_std = mean + (stdev*2)\n",
    "\n",
    "normalize = colors.Normalize(vmin=rededge_min_std, vmax=rededge_max_std, clip=True)\n",
    "imrededge = plt.imshow(rededge, cmap='PuRd_r', norm=normalize)\n",
    "\"\"\"\n",
    "# May not work if older version of NumPy, changed from \"interpolation\" to \"method\", so add try/except block.\n",
    "try:\n",
    "    perc = np.percentile(rededge, [2, 98], method=\"linear\")\n",
    "except:\n",
    "    perc = np.percentile(rededge, [2, 98], interpolation=\"linear\")\n",
    "\n",
    "print (perc)\n",
    "\n",
    "# Call our normalize function as before.\n",
    "normalize = colors.Normalize(vmin=perc[0], vmax=perc[1], clip=True)\n",
    "imrededge = plt.imshow(rededge, cmap='PuRd_r', norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a3a4e-e873-4fab-a9c8-c0ce8e41ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "stdev = np.nanstd(nir)\n",
    "mean = np.nanmean(nir)\n",
    "\n",
    "print(stdev)\n",
    "print(mean)\n",
    "\n",
    "nir_min_std = mean - (stdev*2)\n",
    "nir_max_std = mean + (stdev*2)\n",
    "\n",
    "normalize = colors.Normalize(vmin=nir_min_std, vmax=nir_max_std, clip=True)\n",
    "imnir = plt.imshow(nir, cmap='gray', norm=normalize)\n",
    "\"\"\"\n",
    "\n",
    "# May not work if older version of NumPy, changed from \"interpolation\" to \"method\", so add try/except block.\n",
    "try:\n",
    "    perc = np.percentile(nir, [2, 98], method=\"linear\")\n",
    "except:\n",
    "    perc = np.percentile(nir, [2, 98], interpolation=\"linear\")\n",
    "\n",
    "print (perc)\n",
    "\n",
    "# Call our normalize function as before.\n",
    "normalize = colors.Normalize(vmin=perc[0], vmax=perc[1], clip=True)\n",
    "imnir = plt.imshow(nir, cmap='gray', norm=normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf2507-41ce-4d11-9456-092e7fd2b392",
   "metadata": {},
   "source": [
    "## Computing NDWI\n",
    "\n",
    "Remember from the start that we talked about NDWI, so now let's actually do the calculation for it. NDWI\n",
    "is calculated by the following equation:\n",
    "\n",
    "\\begin{equation}\n",
    "(Green - NIR) / (Green + NIR)\n",
    "\\end{equation}\n",
    "\n",
    "We can do this directly on our entire NumPy arrays, so let's do that now and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1512a-9c64-4da5-b1ca-f4346ff81a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see about doing a simple land/water mask. Note that these can be notoriously tricky based\n",
    "# on various factors such as sun glint, water turbidity, sedimentation, algal content, etc.\n",
    "\n",
    "# First, let's create a NDWI image. There are two versions of NDWI, one of which uses SWIR and the other\n",
    "# which uses the green band. We don't have SWIR, but that's primarily to look for water content in leaves,\n",
    "# whereas the green band version looks for water in water bodies, which is what we want.\n",
    "\n",
    "# NDWI is (Green - NIR)/(Green + NIR)\n",
    "ndwi = (green - nir) / (green + nir)\n",
    "stdev = np.nanstd(ndwi)\n",
    "mean = np.nanmean(ndwi)\n",
    "\n",
    "normalize = colors.Normalize(vmin=(mean - (stdev*2)), vmax=(mean + (stdev*2)), clip=True)\n",
    "imndwi = plt.imshow(ndwi, cmap='Spectral', norm=normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bae28f8-e975-47b9-9a33-8fc815cdb96e",
   "metadata": {},
   "source": [
    "### Classifying NDWI Using a Simple Threshold\n",
    "\n",
    "Going by what we learned about NDWI, we know that values greater than 0 are typically considered water\n",
    "(or flooding/humidity), so we will use the NumPy where function to create a conditional that sets values\n",
    "greater than 0 to a 1 (which we're going to consider water), and otherwise set it to a 2 (which we will\n",
    "consider land).\n",
    "\n",
    "We will also arbitrarily add a threshold check for NIR that says anything less than 0.1 should be water\n",
    "and everything above is not, which may help with some false positives in NDWI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493f14b-6a6d-4ba1-8348-4cf258a4415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using somewhat arbitrary thresholds, let's compute a land/water mask. NDWI defines greater than zero\n",
    "# as water. We'll also use our NIR band as well to apply a little extra filtering - sometimes NDWI can\n",
    "# give some false readings, and NIR will help make sure we're not looking at something that's highly\n",
    "# reflective in the NIR band (possibly in urban environments).\n",
    "\n",
    "classified = np.where(((nir <= 0.1) & (ndwi >= 0)), 1, 2)\n",
    "classified = np.where(np.isnan(nir), nir, classified)\n",
    "imclass = plt.imshow(classified, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a28c8-0c81-44a0-aa51-279be5c60500",
   "metadata": {},
   "source": [
    "## Removing Noise From the Classification\n",
    "\n",
    "This looks pretty decent, but there is some noise present, presumably from smaller objects or sun glint\n",
    "or a host of other in-field issues. So... let's see if we can filter it a bit. First, we're going to try\n",
    "running a Gaussian filter over the NDWI dataset. We'll employ a 5x5 kernel for the smoothing. We can do this\n",
    "using OpenCV's \"GaussianBlur\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f92e3-760b-483f-b463-a9ac783938c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi_blur = cv2.GaussianBlur(ndwi,(5,5),0)\n",
    "\n",
    "classified = np.where(((nir <= 0.1) & (ndwi_blur >= 0)), 1, 2)\n",
    "classified = np.where(np.isnan(nir), nir, classified)\n",
    "imclass = plt.imshow(classified, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b0dd3-30e4-49d3-af42-619e746717a0",
   "metadata": {},
   "source": [
    "This is getting there, but let's do even more to remove some noise. We're going to use GDAL's \"SieveFilter\" function\n",
    "to group pixels together, and eliminate pixel groups less than a given threshold. This function requires an actual\n",
    "GeoTIFF to exist beforehand, so we will create an empty raster that matches our classified raster format.\n",
    "\n",
    "In this case, we will use a threshold of 50, which will keep all connected pixel groups greater than 50 intact,\n",
    "and pixel groups less than that to the adjacent pixel values instead.\n",
    "\n",
    "The \"connectedness\" value determines how adjacent pixels are determined. By default, this is a 4, which means\n",
    "we only count an adjacent pixel if it lies in a cardinal direction. Alternately, you can use a connectedness\n",
    "of 8, which also considers diagonal pixels to the central pixel as connected.\n",
    "\n",
    "### Note about dimensions\n",
    "\n",
    "Be aware that the X and Y sizes might be in a different order when creating a GeoTIFF. In this case, they are\n",
    "transposed from what the shape is of the classified NumPy array and what the GDAL driver expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd925290-d3a6-4dcc-b666-bb1ab266677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to try to filter our imagery a bit more, as this is a bit noisy-looking.\n",
    "\n",
    "\n",
    "# First, we're going to take everywhere that is a NumPy NaN and turn back to zero. This will\n",
    "# effectively become our nodata value.\n",
    "classified_nodata = np.where(np.isnan(classified), 0, classified)\n",
    "\n",
    "# We need to create a temporary GeoTIFF file to store our results in. Be careful with this,\n",
    "# as the rows and columns may be transposed from what the NumPy array holds currently.\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "outdata = driver.Create('{}'.format(\"filter.tif\"), classified.shape[1], classified.shape[0], 1, \\\n",
    "                        gdal.GDT_Byte, options=['COMPRESS=DEFLATE'])\n",
    "\n",
    "# Write our modified classified array to the GeoTIFF we just created, and make sure to add\n",
    "# in our georeferencing as well.\n",
    "outdata.GetRasterBand(1).WriteArray(classified_nodata)\n",
    "outdata.SetGeoTransform(geotransform)\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(wkt)\n",
    "outdata.SetProjection(srs.ExportToWkt())\n",
    "\n",
    "# Now we're going to use GDAL's SieveFilter function to group pixels. There are several options to\n",
    "# change here, but we will stick with a connectedness of 4 (don't consider diagonal pixels adjacent),\n",
    "# and a threshold value of 50 (groups of pixels smaller than 50 will be disregarded).\n",
    "\n",
    "gdal.SieveFilter(srcBand=outdata.GetRasterBand(1), maskBand=None, dstBand=outdata.GetRasterBand(1), threshold=50, connectedness=4)\n",
    "outdata.GetRasterBand(1).SetNoDataValue(0)\n",
    "outdata.FlushCache()\n",
    "\n",
    "# Let's take a look at the results!\n",
    "flt = gdal.Open(\"filter.tif\")\n",
    "fltimg = flt.GetRasterBand(1).ReadAsArray()\n",
    "nodata = flt.GetRasterBand(1).GetNoDataValue()\n",
    "fltimg = np.where(fltimg == nodata, np.nan, fltimg)\n",
    "imflt = plt.imshow(fltimg, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8338e-618a-4af4-b0c5-a8f958d9ed98",
   "metadata": {},
   "source": [
    "## Converting the Classification to a Shapefile\n",
    "\n",
    "Having a classification is useful, but often we don't want to distribute this sort of information as a raster,\n",
    "but instead as a shapefile. We can convert this raster to a shapefile as well. We can use OGR from GDAL to\n",
    "create a shapefile, and then create layers and fields in that shapefile.\n",
    "\n",
    "After this, we can use the \"Polygonize\" function to convert the raster areas into a polygon shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c24b40-e024-46d2-9c0a-7fc894468c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GeoTIFF to shapefile.\n",
    "\n",
    "# Jupyter notebook tends to hold on to this file, so need to manually delete if re-running\n",
    "# this is desired.\n",
    "\n",
    "if not os.path.exists(\"filter.shp\"):\n",
    "    \n",
    "    dstlayername = \"filter.shp\"\n",
    "    drv = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    dstds = drv.CreateDataSource(dstlayername)\n",
    "\n",
    "    # Make sure that a value field exists in the shapefile so that when we call\n",
    "    # Polygonize the values will migrate over.\n",
    "    dstlayer = dstds.CreateLayer(dstlayername, srs=srs, geom_type=ogr.wkbMultiPolygon)\n",
    "    datafield = ogr.FieldDefn('Value', ogr.OFTInteger)\n",
    "    dstlayer.CreateField(datafield)\n",
    "    dstfield = dstlayer.GetLayerDefn().GetFieldIndex(\"Value\")\n",
    "    \n",
    "    # Call Polygonize to change the raster to polygons. The \"8CONNECTEDNESS\" field may not\n",
    "    # be necessary depending on how you want to group pixels (only adjacent in four cardinal\n",
    "    # directions or also on diagonals).\n",
    "    gdal.Polygonize(flt.GetRasterBand(1), None, dstlayer, dstfield, [\"8CONNECTEDNESS=8\"], callback=None)\n",
    "    dstds.SyncToDisk()\n",
    "    dstds=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4879a21-ed9f-459b-80a7-dbc9e6fd8bc9",
   "metadata": {},
   "source": [
    "This is going to closely follow the raster lines, so it will have a jagged appearance. Maybe we don't\n",
    "want that, so we can simplify our shapefile above to have simpler shapes using the \"Simplify\" function.\n",
    "\n",
    "### Note about simplification\n",
    "The simplification may actually remove shapes entirely if they're rather small or already very simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa340d96-6203-4681-a8a3-6847af88d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perhaps we want to simplify this shapefile to be a bit less pixelated.\n",
    "\n",
    "dstlayername = \"filter_simple.shp\"\n",
    "drv = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "dstds = drv.CreateDataSource(dstlayername)\n",
    "dstlayer = dstds.CreateLayer(dstlayername, srs=srs, geom_type=ogr.wkbMultiPolygon)\n",
    "\n",
    "# We want to keep all our fields from the prior shapefile, so create both fields\n",
    "# to match, including FID.\n",
    "datafield = ogr.FieldDefn('Value', ogr.OFTInteger)\n",
    "dstlayer.CreateField(datafield)\n",
    "datafield = ogr.FieldDefn('FID', ogr.OFTInteger)\n",
    "dstlayer.CreateField(datafield)\n",
    "\n",
    "shp = ogr.Open('filter.shp')\n",
    "# Grab the layer.\n",
    "layer = shp.GetLayer()\n",
    "# Find out how many features (polygons) are in our layer.\n",
    "numfeatures = layer.GetFeatureCount()\n",
    "\n",
    "# Iterate through each feature in the shapeifle and simplify the geometry.\n",
    "# Note that this may actually completely remove some shapes.\n",
    "for i in range(0, numfeatures):\n",
    "    feature = layer.GetFeature(i)\n",
    "    geometry = feature.geometry()\n",
    "    feature.SetGeometry(geometry.Simplify(0.1))\n",
    "    dstlayer.CreateFeature(feature)\n",
    "    #print(filter_simple)\n",
    "    #print(geometry)\n",
    "\n",
    "dstds.SyncToDisk()\n",
    "dstds=None\n",
    "shp=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a2c89-713c-4936-a11e-9b41955f5e61",
   "metadata": {},
   "source": [
    "## Adding Otsu's Method For Binary Thresholding\n",
    "Otsu's method is a technique for looking at bimodal distributions and determining the optimal split\n",
    "point for that distribution. The paper here argues for using Otsu's method for adjusting the\n",
    "threshold for various NDWI indices based on the area, image quality, lighting conditions, and so\n",
    "forth.\n",
    "\n",
    "https://doi.org/10.1016/j.envsoft.2021.105030"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3c892-de86-4f23-afbe-3b92bc220399",
   "metadata": {},
   "source": [
    "### Applying Otsu's method to the NIR band only\n",
    "\n",
    "Technically outside of the scope of the paper above, but if we were to only use the NIR band to\n",
    "attempt water delineation, then we might still use Otsu's method to split out our distribution.\n",
    "\n",
    "#### Converting from 32-bit float to 8-bit integer array\n",
    "\n",
    "Otsu's method, as implemented in OpenCV, only supports 8-bit grayscale imagery. Our NIR data\n",
    "is already grayscale since we've only selected that band, but it is in floating-point format,\n",
    "so we need to convert to 8-bit. Note that we will lose some granularity in this conversion.\n",
    "\n",
    "#### Applying the threshold\n",
    "\n",
    "The \"threshold\" function can give us both an image as well as the actual threshold values. We're\n",
    "doing a binary threshold, and to specify that we're using Otsu's method, we also need to add in\n",
    "\"cv2.THRESH_OTSU\" to work. We can convert the image output and our threshold back to floating-point\n",
    "and our image classes after we get them back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84625f-c1df-4c50-9ffd-86cc3af63841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns out Otsu's threshold in OpenCV wants an 8-bit array. Let's oblige them.\n",
    "nir8bit = np.array(nir*255, dtype='uint8')\n",
    "\n",
    "# Use Otsu's method to compute an automatic threshold.\n",
    "otsu_threshold, image_result = cv2.threshold(nir8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "otsu_threshold_float = otsu_threshold / 255.0\n",
    "print (\"Threshold:\", otsu_threshold_float)\n",
    "\n",
    "print (image_result)\n",
    "\n",
    "# Remap to 1 and 2 for values, aligning with our previous classification values.\n",
    "newarr = np.where(image_result == 255, 2, image_result)\n",
    "newarr = np.where(newarr == 0, 1, newarr)\n",
    "\n",
    "print (newarr)\n",
    "# And now we can compare this result to our initial classification.\n",
    "otsuimg = plt.imshow(newarr, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945bc7e-9df6-4975-89f3-0a7c7f29f763",
   "metadata": {},
   "source": [
    "Whew, looking pretty noisy! In some ways it's capturing more of the water than the last attempt, though. This\n",
    "is a pretty challenging environment for NDWI, as it's in a marshy wetland area, and much of what is visible\n",
    "is aquatic plants both native and invasive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb52b09-665e-4f9c-8a16-e4ed8bcf4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a gaussian filter on this.\n",
    "nir8bit = cv2.GaussianBlur(nir8bit,(5,5),0)\n",
    "\n",
    "# Use Otsu's method to compute an automatic threshold.\n",
    "otsu_threshold, image_result = cv2.threshold(nir8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "otsu_threshold_float = otsu_threshold / 255.0\n",
    "print (otsu_threshold_float)\n",
    "\n",
    "print (image_result)\n",
    "\n",
    "# remap to 1 and 2 for values.\n",
    "newarr = np.where(image_result == 255, 2, image_result)\n",
    "newarr = np.where(newarr == 0, 1, newarr)\n",
    "\n",
    "print (newarr)\n",
    "# And now we can compare this result to our initial classification.\n",
    "otsuimg = plt.imshow(newarr, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4dfc52-ceba-41dd-be64-30cfa16f55f2",
   "metadata": {},
   "source": [
    "## Applying Otsu's Method to NDWI\n",
    "\n",
    "What we see above indicates that perhaps using NIR alone is overly sensitive in this area - it's just not enough\n",
    "by itself to keep from making errors of commission. So we shift back to NDWI to take another stab at it.\n",
    "\n",
    "This looks similar to before, including converting to an 8-bit grayscale image, however, since NDWI will run from\n",
    "-1 to 1, we need to scale it differently to get it into a range from 0-255. We're also going to use the Gaussian\n",
    "blurred version to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a4ab4-9e02-4a13-bd3f-934381c0a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns out Otsu's threshold in OpenCV wants an 8-bit array. Let's oblige them.\n",
    "# NDWI is from -1 to 1, so... have to scale it differently.\n",
    "# Also going to use Gaussian blur version.\n",
    "ndwi8bit = np.array((ndwi_blur+1.0)*128, dtype='uint8')\n",
    "print (ndwi8bit)\n",
    "\n",
    "otsu_threshold, image_result = cv2.threshold(ndwi8bit, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "otsu_threshold_float = (otsu_threshold/128.0) - 1.0\n",
    "print (\"Threshold:\", otsu_threshold_float)\n",
    "newarr2 = np.where(image_result == 0, 1, image_result)\n",
    "newarr2 = np.where(newarr2 == 255, 2, newarr2)\n",
    "otsuimg = plt.imshow(newarr2, cmap='coolwarm')\n",
    "print (image_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb02307-2279-4921-8a1b-1bfe6d4dcb17",
   "metadata": {},
   "source": [
    "This looks pretty solid! But let's still filter it just a tiny bit more. We'll try the sieve filter again to\n",
    "clean it up a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910407e1-36a5-4472-a3b2-59ca98ba3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to try to filter our imagery a bit more, as this is a bit noisy-looking.\n",
    "\n",
    "\n",
    "# First, we're going to take everywhere that is a NumPy NaN and turn back to zero. This will\n",
    "# effectively become our nodata value.\n",
    "newarr2_nodata = np.where(np.isnan(newarr2), 0, newarr2)\n",
    "\n",
    "# We need to create a temporary GeoTIFF file to store our results in. Be careful with this,\n",
    "# as the rows and columns may be transposed from what the NumPy array holds currently.\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "outdata = driver.Create('{}'.format(\"filter_otsu.tif\"), classified.shape[1], classified.shape[0], 1, \\\n",
    "                        gdal.GDT_Byte, options=['COMPRESS=DEFLATE'])\n",
    "\n",
    "# Write our modified classified array to the GeoTIFF we just created, and make sure to add\n",
    "# in our georeferencing as well.\n",
    "outdata.GetRasterBand(1).WriteArray(newarr2_nodata)\n",
    "outdata.SetGeoTransform(geotransform)\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(wkt)\n",
    "outdata.SetProjection(srs.ExportToWkt())\n",
    "\n",
    "# Now we're going to use GDAL's SieveFilter function to group pixels. There are several options to\n",
    "# change here, but we will stick with a connectedness of 4 (don't consider diagonal pixels adjacent),\n",
    "# and a threshold value of 50 (groups of pixels smaller than 50 will be disregarded).\n",
    "\n",
    "gdal.SieveFilter(srcBand=outdata.GetRasterBand(1), maskBand=None, dstBand=outdata.GetRasterBand(1), threshold=50, connectedness=4)\n",
    "outdata.GetRasterBand(1).SetNoDataValue(0)\n",
    "outdata.FlushCache()\n",
    "\n",
    "# Let's take a look at the results!\n",
    "flt_otsu = gdal.Open(\"filter_otsu.tif\")\n",
    "flt_otsu_img = flt_otsu.GetRasterBand(1).ReadAsArray()\n",
    "nodata = flt.GetRasterBand(1).GetNoDataValue()\n",
    "flt_otsu_img = np.where(flt_otsu_img == nodata, np.nan, flt_otsu_img)\n",
    "imflt_otsu = plt.imshow(flt_otsu_img, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f4c18-330b-4e01-b67f-da27a5eb42fc",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Compared to the first approach with a zero breakpoint, you can see that we're picking up a bit more water that's\n",
    "in the area. But we're also picking up the airboat to the right side of the image, which is a problem with NDWI\n",
    "in urban environments that is also mirrored by having similar image characteristics on the boat.\n",
    "\n",
    "We can visualize the difference between the first and second attempts by checking where the two are equal. The\n",
    "bright yellow spots are where the second attempt picked up water where the first did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953ad23-2ffc-484a-bd62-266909d9ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the difference between this and our original version.\n",
    "\n",
    "diff = np.where(newarr2 != fltimg, 2, 1)\n",
    "plt.imshow(diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pyworkshop] *",
   "language": "python",
   "name": "conda-env-.conda-pyworkshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
